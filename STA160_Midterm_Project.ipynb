{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tspacel/gh-usernames/blob/master/STA160_Midterm_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0mHB6rEwC0b"
      },
      "source": [
        "# STA 160 Midterm Project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OACHQrdU6_HG"
      },
      "source": [
        "## 1.1 Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4ngLM3azIK4"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7Z9orh4zVkl"
      },
      "outputs": [],
      "source": [
        "\n",
        "#load data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjHyJaze0RT7"
      },
      "outputs": [],
      "source": [
        "#drive.mount('/content/gdrive')\n",
        "path = '/gdrive/MyDrive/heart_disease_health_indicators_BRFSS2015.csv'\n",
        "heart_disease = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1t4TSbF7Hz5"
      },
      "source": [
        "## 1.2 Overview of the data structure and outline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0LDMiWg6kkp"
      },
      "outputs": [],
      "source": [
        "print (heart_disease.head(10))\n",
        "print( heart_disease.describe())\n",
        "print(heart_disease.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFZDX2Ne6748"
      },
      "source": [
        "From the out put above we can see that the dataset contains 253680 rows of data and 21 different columns , each rows are make up by the non-null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJz2MjGpezfo"
      },
      "source": [
        "### Dimionation reduction to creat the 2x2 dim contingency table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRY6VYgt61Lu"
      },
      "outputs": [],
      "source": [
        "data_crosstab = pd.crosstab(heart_disease['HighBP'],\n",
        "                            heart_disease['HeartDiseaseorAttack'], \n",
        "                            margins = False)\n",
        "print(data_crosstab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHriZxb2e_aX"
      },
      "outputs": [],
      "source": [
        "data_crosstab = pd.crosstab([heart_disease.HighBP, heart_disease.HighChol], \n",
        "                             heart_disease.HeartDiseaseorAttack, margins = False)\n",
        "print(data_crosstab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn3DhkSBh96k"
      },
      "outputs": [],
      "source": [
        "data_crosstab = pd.crosstab([heart_disease.HighBP, heart_disease.HighChol,heart_disease.Age], \n",
        "                             heart_disease.HeartDiseaseorAttack, margins = False)\n",
        "print(data_crosstab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCc0aGkWjy0h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the feature columns and target column\n",
        "features = ['HighBP', 'HighChol', 'Age']\n",
        "target = 'HeartDiseaseorAttack'\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(heart_disease[features], \n",
        "                                                    heart_disease[target], \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42)\n",
        "\n",
        "# Initialize the decision tree classifier with a maximum depth of 3\n",
        "clf = DecisionTreeClassifier(max_depth=3)\n",
        "\n",
        "# Train the classifier on the training set\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Plot the decision tree\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_tree(clf, feature_names=features, class_names=['No Disease', 'Disease'], filled=True)\n",
        "plt.show()\n",
        "\n",
        "# Use the trained classifier to make predictions on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the accuracy score of the classifier\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjGNSsYYk1fG"
      },
      "source": [
        "In this program, we first load the 'heart_disease' dataset using pandas and define the feature columns ('HighBP', 'HighChol', and 'Age') and the target column ('HeartDiseaseorAttack'). We then split the data into training and testing sets using the train_test_split function from scikit-learn.\n",
        "\n",
        "Next, we initialize a decision tree classifier with a maximum depth of 3 and train it on the training set using the fit method. Finally, we plot the resulting decision tree using the plot_tree function from scikit-learn, which takes as input the trained classifier (clf), the feature names (features), the class names ('No Disease' and 'Disease'), and the filled argument, which fills the tree nodes with colors according to the class distribution. We also set the figsize argument to (10, 6) to make the plot larger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BxDz-HTkzS1"
      },
      "outputs": [],
      "source": [
        "# Bin the data by age\n",
        "age_bins = heart_disease['Age']\n",
        "\n",
        "# Calculate the conditional probability of HeartDiseaseorAttack for each combination of HighBP, HighChol, and Age\n",
        "heart_disease_cond_prob = heart_disease.groupby(['HighBP', 'HighChol', 'Age'])['HeartDiseaseorAttack'].mean().reset_index()\n",
        "\n",
        "# Plot the conditional probability as a histogram for each combination of HighBP and HighChol\n",
        "for high_bp in [0, 1]:\n",
        "    for high_chol in [0, 1]:\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.hist(heart_disease_cond_prob[(heart_disease_cond_prob['HighBP'] == high_bp) & (heart_disease_cond_prob['HighChol'] == high_chol)]['HeartDiseaseorAttack'], bins=20, alpha=0.5, label='Heart Disease')\n",
        "        plt.xlabel('Conditional Probability of Heart Disease')\n",
        "        plt.ylabel('Count')\n",
        "        plt.title('Conditional Probability of Heart Disease Given HighBP={} and HighChol={}'.format(high_bp, high_chol))\n",
        "        plt.legend()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsEXhmxpl4ql"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import entropy\n",
        "\n",
        "# Calculate the conditional entropy of HeartDiseaseorAttack for each combination of HighBP, HighChol, and Age\n",
        "heart_disease_cond_entropy = heart_disease.groupby(['HighBP', 'HighChol', 'Age'])['HeartDiseaseorAttack'].apply(lambda x: entropy(np.histogram(x, bins=[0, 0.5, 1])[0], base=2)).reset_index()\n",
        "heart_disease_cond_entropy = heart_disease_cond_entropy.rename(columns={'HeartDiseaseorAttack': 'Entropy'})\n",
        "age = heart_disease.Age\n",
        "# Plot the conditional entropy as a heatmap for each combination of HighBP and HighChol\n",
        "heatmap_data = heart_disease_cond_entropy.pivot(index=['Age', 'HighBP'], columns='HighChol', values='Entropy')\n",
        "plt.imshow(heatmap_data, cmap='YlOrRd', interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.xticks(np.arange(len([0, 1])), [0, 1])\n",
        "#plt.yticks(age)\n",
        "plt.xlabel('HighChol')\n",
        "plt.ylabel('Age')\n",
        "plt.title('Conditional Entropy of Heart Disease Given HighBP and HighChol')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## "
      ],
      "metadata": {
        "id": "9Xw4-ml4xxKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define feature columns and target column\n",
        "feature_cols = ['HighBP', 'HighChol', 'Age']\n",
        "target_col = 'HeartDiseaseorAttack'\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(heart_disease[feature_cols], heart_disease[target_col], test_size=0.2, random_state=42)# Split the data into training and testing sets\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(len(feature_cols),)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data, train_labels, epochs=50, batch_size=32, validation_data=(test_data, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "DChfpO6ww0jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this program, we first load the 'heart_disease' dataset using pandas and define the feature columns ('HighBP', 'HighChol', and 'Age') and the target column ('HeartDiseaseorAttack'). We then split the data into training and testing sets using the train_test_split function from scikit-learn.\n",
        "\n",
        "Next, we define the DNN using TensorFlow's Sequential API. The model has three layers: the first two are fully connected (Dense) layers with 64 and 32 neurons, respectively, and ReLU activation functions; the third layer is a fully connected layer with one neuron and a sigmoid activation function, which outputs a probability of the positive class (disease).\n",
        "\n",
        "We compile the model by specifying the optimizer (adam), loss function (binary_crossentropy), and metric to optimize (accuracy).\n",
        "\n",
        "We train the model on the training data using the fit method, with 50 epochs and a batch size of 32. We also pass in the testing data to evaluate the model's performance on unseen data."
      ],
      "metadata": {
        "id": "v8ODjBmkxs1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot the training and validation accuracy over epochs\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot the training and validation loss over epochs\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mB6_Hwa-yftg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a dataframe for HighBP\n",
        "high_bp_df = heart_disease[heart_disease['HighBP'] == 1]\n",
        "\n",
        "# Create a dataframe for normal BP\n",
        "normal_bp_df = heart_disease[heart_disease['HighBP'] == 0]\n",
        "\n",
        "# Create a dataframe for HighChol\n",
        "high_chol_df = heart_disease[heart_disease['HighChol'] == 1]\n",
        "\n",
        "# Create a dataframe for normal Chol\n",
        "normal_chol_df = heart_disease[heart_disease['HighChol'] == 0]\n"
      ],
      "metadata": {
        "id": "IH0u0_gM96T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('heart_disease.csv')\n",
        "\n",
        "# Define the feature columns and the target column\n",
        "features = ['HighBP', 'HighChol', 'Age']\n",
        "target = 'HeartDiseaseorAttack'\n",
        "\n",
        "# Compute the conditional entropy of the target column based on the feature columns\n",
        "entropy = {}\n",
        "for col in features:\n",
        "    for val in set(data[col]):\n",
        "        subdata = data[data[col] == val]\n",
        "        p = subdata[target].value_counts(normalize=True)\n",
        "        entropy[(col, val)] = -np.sum(p * np.log2(p))\n",
        "\n",
        "# Plot the conditional entropy as a line chart\n",
        "x = np.arange(len(entropy))\n",
        "y = list(entropy.values())\n",
        "labels = ['{}={}'.format(*k) for k in entropy.keys()]\n",
        "plt.plot(x, y)\n",
        "plt.xticks(x, labels, rotation='vertical')\n",
        "plt.xlabel('Condition')\n",
        "plt.ylabel('Entropy')\n",
        "plt.title('Conditional Entropy of HeartDiseaseorAttack')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kAZyeHYPzOKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the feature columns and the target column\n",
        "features = ['Age']\n",
        "target = 'HeartDiseaseorAttack'\n",
        "\n",
        "# Compute the conditional entropy of the target column based on the feature columns\n",
        "entropy = {}\n",
        "for col in features:\n",
        "    for val in set(normal_bp_df[col]):\n",
        "        subdata = normal_bp_df[normal_bp_df[col] == val]\n",
        "        p = subdata[target].value_counts(normalize=True)\n",
        "        entropy[(col, val)] = -np.sum(p * np.log2(p))\n",
        "\n",
        "# Plot the conditional entropy as a line chart\n",
        "x = np.arange(len(entropy))\n",
        "y = list(entropy.values())\n",
        "labels = ['{}={}'.format(*k) for k in entropy.keys()]\n",
        "plt.plot(x, y)\n",
        "plt.xticks(x, labels, rotation='vertical')\n",
        "plt.xlabel('Condition')\n",
        "plt.ylabel('Entropy')\n",
        "plt.title('Conditional Entropy of HeartDiseaseorAttack')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EaXv_-Od-XQj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}